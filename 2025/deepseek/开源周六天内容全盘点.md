上周五，DeepSeek 开源了 7 款相当硬核的产品， 涵盖了AI的计算、通信、存储等多个领域。 周六还揭露了deepseek R1 和 V3的赚钱逻辑。

# FlashMLA
FlashMLA是专门针对英伟达Hopper GPU 的ML加速器。 多头潜在注意力。支持BF16, KV缓存。 FlashAttention2/3 的实现。 FlashAttention是对Transformer模型的自注意力机制的优化。目标是减少显存的占用，加速计算。 在H800上 实现了3000GB/s 和 580TFlops的计算性能。 同时将时间复杂度和空间复杂度从MHA的O(n^2) 降低到了O(nk)。 使得它非常适合处理文档分析这类的长序列任务。

# DeepEP
专门为混合专家系统MoE和专家并行EP定制的通信库。 参数越来越大，高效通信成为瓶颈。 MoE有资源分配不均衡导致的效率低下。

# DeepGEMM
为FP8矩阵乘法设计的库。 实现1350+的FP8 Flops.

# DualPipe
前向计算，反向传播。 效率低。 要同时进行。

# 3FS
DeepEP 榨干GPU， 3FS 榨干SSD。 

24小时内，平均使用226.75个节点。每个节点8个H800, 每个GPU每小时租金2美元。 每天8万多刀。 token日收入56万多刀。 5倍多的利润率。